# AI 개발 workflow
1. 데이터 수집 및 데이터 로드
2. 데이터 분석
3. 데이터 전처리
4. __모델 학습(머신러닝/딥러닝)__
5. 모델 성능 평가

<br/>

## 4. 모델 학습(머신러닝/딥러닝)

<br/>

### 1) 머신러닝

#### <회귀>

###### #선형회귀
from sklearn.linear_model import LinearRegression   
from sklearn.metrics import confusion_matrix   
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score   
from sklearn.metrics import classification_report   

model = LinearRegression()   
model.fit(x_train, y_train)   
y_pred = model.predict(x_test)   
print(classification_report(y_test, y_pred))   

<br/>

#### <분류>

###### #로지스틱 회귀
from sklearn.linear_model import LogisticRegression   
from sklearn.metrics import confusion_matrix   
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score   
from sklearn.metrics import classification_report   

model = LogisticRegression()   
model.fit(x_train, y_train)   
y_pred = model.predict(x_test)   
print(classification_report(y_test, y_pred))   

###### #의사결정트리
from sklearn.tree import DecisionTreeClassifier   
from sklearn.metrics import confusion_matrix   
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score   
from sklearn.metrics import classification_report   

model = DecisionTreeClassifier()   
model.fit(x_train, y_train)   
y_pred = model.predict(x_test)   
print(classification_report(y_test, y_pred))   

###### #랜덤포레스트
from sklearn.ensemble import RandomForestClassifier   
from sklearn.metrics import confusion_matrix   
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score   
from sklearn.metrics import classification_report   

model = RandomForestClassifier()   
model.fit(x_train, y_train)   
y_pred = model.predict(x_test)   
print(classification_report(y_test, y_pred))   

<br/>

### 2) 딥러닝

import tensorflow as tf   
from tensorflow.keras.backend import clear_session   
from tensorflow.keras.models import Sequential   
from tensorflow.keras.layers import Dense, Dropout, Input   
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint   

###### #데이터의 행, 열 개수 찾기
x_train.shape

###### #이진 분류 모델 생성
clear_session()   
model = Sequential([   
    Input(shape=(18,)),  #input shape : 입력데이터의 shape(열의 개수) 반드시 명시   
    Dense(64, activation='relu'),   
    Dropout(0.2),   
    Dense(32, activation='relu'),   
    Dropout(0.2),   
    Dense(16, activation='relu'),   
    Dropout(0.2),   
    Dense(1, activation='sigmoid')   
    #다중 분류   
    #Dense('최종output 레이어 개수', activation='softmax')   
])
model.summary()   

###### #모델 컴파일 optimizer 설정 -> loss:손실함수, metrics:평가기준
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
###### #다중분류
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc']) #원핫인코딩된 경우   
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc']) #원핫인코딩 안된 경우   
###### #회귀
model.compile(optimizer='adam', loss='mse', metrics=['mse','mae'])

###### #callback 함수 설정
es = EarlyStopping(monitor='val_loss', patience=4, mode='min', verbose=1)   
mc = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)   

###### #학습하기
hist = model.fit(x_train, y_train,   
                batch_size=32,   
                epochs=100,   
                callbacks=[es, mc],   
                validation_data=(x_test, y_test),   
                verbose=1)   

